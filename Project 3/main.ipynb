{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3749b76e893bd4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:51.441222Z",
     "start_time": "2024-04-24T20:54:51.437790Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b216aac8fa49f71",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:51.633032Z",
     "start_time": "2024-04-24T20:54:51.629357Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(256)\n",
    "torch.cuda.manual_seed(256)\n",
    "np.random.seed(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ebf58a160f821f6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:51.791289Z",
     "start_time": "2024-04-24T20:54:51.783983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f18624e811dc2d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1 Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdeb62e62883d05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Read txt files and tokenize them to obtain train/validation/test lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180dd603429352f4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:52.299959Z",
     "start_time": "2024-04-24T20:54:52.293310Z"
    }
   },
   "outputs": [],
   "source": [
    "TOKENIZER = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "def read_txt_files(datapath):\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith(\".txt\")]\n",
    "\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name) as f:\n",
    "            lines += f.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def tokenize(lines, tokenizer=TOKENIZER):\n",
    "    list_text = []\n",
    "    for line in lines:\n",
    "        list_text += tokenizer(line)\n",
    "    return list_text\n",
    "\n",
    "\n",
    "def yield_tokens(lines, tokenizer=TOKENIZER):\n",
    "    no_digits = \"\\w*[0-9]+\\w*\"  # Regex to match words containing numbers\n",
    "    no_names = \"\\w*[A-Z]+\\w*\"  # Regex to match words with capital letters (names)\n",
    "    no_spaces = \"\\s+\"  # Regex to match sequences of whitespace\n",
    "\n",
    "    # Processing each line to remove digits, names, and extra spaces\n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits, \" \", line)\n",
    "        line = re.sub(no_names, \" \", line)\n",
    "        line = re.sub(no_spaces, \" \", line)\n",
    "        # Yielding the tokenized and cleaned line\n",
    "        yield tokenizer(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e46a7ce8b9c09f97",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:52.857009Z",
     "start_time": "2024-04-24T20:54:52.444575Z"
    }
   },
   "outputs": [],
   "source": [
    "GENERATED_PATH = \"./generated/\"  # Path where generated data files are stored\n",
    "\n",
    "# Check if the training data file already exists in the generated path\n",
    "if os.path.isfile(GENERATED_PATH + \"words_train.pt\"):\n",
    "    # Load preprocessed training, validation, and test word lists from .pt files\n",
    "    words_train = torch.load(GENERATED_PATH + \"words_train.pt\")\n",
    "    words_val = torch.load(GENERATED_PATH + \"words_val.pt\")\n",
    "    words_test = torch.load(GENERATED_PATH + \"words_test.pt\")\n",
    "else:\n",
    "    # If preprocessed data does not exist, read text files\n",
    "    lines_books_train = read_txt_files(\"data/data_train/\")\n",
    "    lines_books_val = read_txt_files(\"data/data_val/\")\n",
    "    lines_books_test = read_txt_files(\"data/data_test/\")\n",
    "\n",
    "    # Tokenize the lines from train, validation, and test datasets\n",
    "    words_train = tokenize(lines_books_train)\n",
    "    words_val = tokenize(lines_books_val)\n",
    "    words_test = tokenize(lines_books_test)\n",
    "\n",
    "    # Save the tokenized word lists to .pt files\n",
    "    torch.save(words_train, GENERATED_PATH + \"words_train.pt\")\n",
    "    torch.save(words_val, GENERATED_PATH + \"words_val.pt\")\n",
    "    torch.save(words_test, GENERATED_PATH + \"words_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6615cee6d135c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Define a vocabulary based on the training dataset. To avoid getting a too large vocabulary, a solution can be to keep only words that appear at least 100 times in the training dataset. Report the total number of words in the training dataset, the number of distinct words in the training dataset, and the size of the defined vocabulary. Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79cd1cab7154c135",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:52.863073Z",
     "start_time": "2024-04-24T20:54:52.858556Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 100\n",
    "\n",
    "\n",
    "def create_vocabulary(lines, min_freq=MIN_FREQ):\n",
    "    # Building vocabulary from an iterator of tokenized lines, filtering out infrequent tokens\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"])\n",
    "    # Appending token \"I\", since we removed all words with an uppercase when building the vocabulary\n",
    "    vocab.append_token(\"i\")\n",
    "    # Setting default index for unknown words\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf7baee7fcace153",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:52.990992Z",
     "start_time": "2024-04-24T20:54:52.971473Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_FILENAME = \"vocabulary.pt\"\n",
    "\n",
    "# Check if the vocabulary file already exists in the generated path\n",
    "if os.path.isfile(GENERATED_PATH + VOCAB_FILENAME):\n",
    "    # Load the vocabulary from a file if it already exists\n",
    "    vocab = torch.load(GENERATED_PATH + VOCAB_FILENAME)\n",
    "else:\n",
    "    # If the vocabulary file does not exist, create a new vocabulary from training data\n",
    "    vocab = create_vocabulary(lines_books_train, min_freq=MIN_FREQ)\n",
    "    # Save the newly created vocabulary to a file\n",
    "    torch.save(vocab, GENERATED_PATH + VOCAB_FILENAME)\n",
    "\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f174be539d0b11b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:53.232940Z",
     "start_time": "2024-04-24T20:54:53.231072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset: 2,684,706\n",
      "Total number of words in the validation dataset: 49,526\n",
      "Total number of words in the test dataset: 124,152\n",
      "\n",
      "Number of distinct words in the training dataset: 52,105\n",
      "Number of distinct words in the validation dataset: 5,778\n",
      "Number of distinct words in the test dataset: 9,585\n",
      "\n",
      "Size of the defined vocabulary: 1,880\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of words in the training dataset: {len(words_train):,}\")\n",
    "print(f\"Total number of words in the validation dataset: {len(words_val):,}\")\n",
    "print(f\"Total number of words in the test dataset: {len(words_test):,}\", end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Number of distinct words in the training dataset: {len(set(words_train)):,}\")\n",
    "print(f\"Number of distinct words in the validation dataset: {len(set(words_val)):,}\")\n",
    "print(f\"Number of distinct words in the test dataset: {len(set(words_test)):,}\", end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Size of the defined vocabulary: {VOCAB_SIZE:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c4165ae11f6e10",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:54:53.308984Z",
     "start_time": "2024-04-24T20:54:53.306766Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_occurrences(words, vocab):\n",
    "    occurrences = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        occurrences[vocab[w]] += 1\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e516a890cd3ce97",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.833924Z",
     "start_time": "2024-04-24T20:54:53.564537Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts_df = pd.DataFrame({\n",
    "    \"Word\": vocab.lookup_tokens(range(len(vocab))),\n",
    "    \"Occurrences\": count_occurrences(words_train, vocab).numpy()\n",
    "})\n",
    "\n",
    "sorted_word_counts = word_counts_df.sort_values(by=\"Occurrences\", ascending=False).reset_index(drop=True)\n",
    "sorted_word_counts.index = sorted_word_counts.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aa1dbc37499968d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.840142Z",
     "start_time": "2024-04-24T20:55:02.836462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                Word  Occurrences\n1              <unk>       433907\n2                  ,       182537\n3                the       151278\n4                  .       123727\n5                and        82289\n...              ...          ...\n1876          pistol          100\n1877         slipped          100\n1878  station-master          100\n1879          wounds          100\n1880           agree          100\n\n[1880 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Occurrences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>&lt;unk&gt;</td>\n      <td>433907</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,</td>\n      <td>182537</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>151278</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>.</td>\n      <td>123727</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>and</td>\n      <td>82289</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1876</th>\n      <td>pistol</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1877</th>\n      <td>slipped</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1878</th>\n      <td>station-master</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1879</th>\n      <td>wounds</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1880</th>\n      <td>agree</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n<p>1880 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1121f0251a057029",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.846869Z",
     "start_time": "2024-04-24T20:55:02.841920Z"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 3  # Number of words considered before and after the target word\n",
    "target_counts = {}\n",
    "\n",
    "\n",
    "def create_context_target_dataset(text, vocab, context_size=CONTEXT_SIZE, max_occurrences=None):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "\n",
    "    # Loop over the words list with enough space to form the context window\n",
    "    for i in range(context_size, len(text) - context_size):\n",
    "        target_word = text[i]\n",
    "\n",
    "        # Skip if the target word is punctuation\n",
    "        if target_word in [',', '.', '(', ')', '?', '!']:\n",
    "            continue\n",
    "\n",
    "        # Convert the word to its vocabulary index, skip if not in vocabulary\n",
    "        target_idx = vocab.get_stoi().get(target_word, None)\n",
    "        if target_idx is None:\n",
    "            continue\n",
    "\n",
    "        # Limit occurrences of each word\n",
    "        if max_occurrences is not None:\n",
    "            if target_word in target_counts and target_counts[target_word] >= max_occurrences:\n",
    "                continue\n",
    "            target_counts[target_word] = target_counts.get(target_word, 0) + 1\n",
    "\n",
    "        # Extract the context words: context_size words before and context_size words after the target word\n",
    "        context = [vocab[text[j]] for j in range(i - context_size, i + context_size + 1) if j != i]\n",
    "        contexts.append(torch.tensor(context))\n",
    "        targets.append(target_idx)\n",
    "\n",
    "    return TensorDataset(torch.stack(contexts), torch.tensor(targets, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec1c029e087bb33a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.889132Z",
     "start_time": "2024-04-24T20:55:02.846175Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(words, vocab, filename, generated_path=GENERATED_PATH):\n",
    "    full_path = os.path.join(generated_path, filename)\n",
    "    if os.path.isfile(full_path):\n",
    "        return torch.load(full_path)\n",
    "    else:\n",
    "        dataset, target_counts = create_context_target_dataset(words, vocab, max_occurrences=10000)\n",
    "        torch.save(dataset, full_path)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "data_train = load_dataset(words_train, vocab, \"data_train.pt\")\n",
    "data_val = load_dataset(words_val, vocab, \"data_val.pt\")\n",
    "data_test = load_dataset(words_test, vocab, \"data_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1,320,520\n",
      "Validation dataset size: 36,216\n",
      "Test dataset size: 83,645\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size: {len(data_train):,}\")\n",
    "print(f\"Validation dataset size: {len(data_val):,}\")\n",
    "print(f\"Test dataset size: {len(data_test):,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.889405Z",
     "start_time": "2024-04-24T20:55:02.867043Z"
    }
   },
   "id": "32c46f4667cd0cd7"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T20:55:02.889457Z",
     "start_time": "2024-04-24T20:55:02.869297Z"
    }
   },
   "id": "ec3168a690e0a5ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Define a continuous bag of words model architecture based on this vocabulary that contains an embedding layer. To drastically reduce the computational cost, the dimension of the embedding `emb_dim` can be very low such as 16, 12, or even 10. Of course, in a real setting, a larger space would be used. You are not allowed to use `nn.LazyLinear` in this project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63eaf39159ad4b4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a7291fb9d6248cd"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        # Embedding layer: maps each word index to a dense vector representation\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        # Linear layer 1: maps flattened context embeddings to a hidden layer\n",
    "        self.lin1 = nn.Linear(context_size * 2 * emb_dim, hidden_dim)\n",
    "        # Activation function: applies ReLU to introduce non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # Linear layer 2: projects from the hidden layer to the output layer of size vocab_size\n",
    "        self.lin2 = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Embeds the input word indices to get dense vector representations\n",
    "        embeds = self.embedding(inputs)\n",
    "        # Flattens the embeddings into a single long vector per sample in the batch\n",
    "        embeds = embeds.view(embeds.size(0), -1)\n",
    "        out = self.lin1(embeds)\n",
    "        out = self.relu(out)\n",
    "        out = self.lin2(out)\n",
    "        # Applies log softmax to compute log probabilities\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:03:15.521722Z",
     "start_time": "2024-04-24T21:03:15.518171Z"
    }
   },
   "id": "9a2231208b9d8d5f"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, loss_fn, epochs=20):\n",
    "    training_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for contexts, targets in train_loader:\n",
    "            contexts, targets = contexts.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(contexts)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        training_losses.append(avg_train_loss)\n",
    "\n",
    "        timestamp = datetime.now().strftime('%H:%M:%S.%f')\n",
    "        print(f\"\\r{timestamp} | Epoch {epoch} | Training Loss: {avg_train_loss:.5f}\", end=\"\")\n",
    "\n",
    "    return training_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:49.954859Z",
     "start_time": "2024-04-24T21:04:49.941727Z"
    }
   },
   "id": "301f3f01ab9ba8c3"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def calculate_weights(data, vocab_size=VOCAB_SIZE):\n",
    "    # Initialize counts with zeros for each possible word index\n",
    "    counts = torch.zeros(vocab_size, dtype=torch.int)\n",
    "\n",
    "    # Count occurrences of each target in the dataset\n",
    "    for _, target in data:\n",
    "        counts[target.item()] += 1\n",
    "\n",
    "    # Total number of samples\n",
    "    total_samples = counts.sum()\n",
    "\n",
    "    # Weights for each class\n",
    "    weights = total_samples / (counts * VOCAB_SIZE)\n",
    "\n",
    "    # Replace inf/NaN with zero (in case some classes do not appear in the counts)\n",
    "    weights[torch.isinf(weights) | torch.isnan(weights)] = 0\n",
    "\n",
    "    # Normalize weights so that their maximum is 1\n",
    "    weights = weights / weights.max()\n",
    "\n",
    "    return weights.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:50.190581Z",
     "start_time": "2024-04-24T21:04:50.186576Z"
    }
   },
   "id": "d2aee5e15b33d61d"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class_weights = calculate_weights(data_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.148792Z",
     "start_time": "2024-04-24T21:04:50.522546Z"
    }
   },
   "id": "2c1f1e7f0bdb68e8"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def save_losses(train_losses, model_name, folder=\"losses\"):\n",
    "    filepath = os.path.join(folder, f\"{model_name}_losses.csv\")\n",
    "    df = pd.DataFrame({\n",
    "        \"train_loss\": train_losses\n",
    "    })\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Losses saved to {filepath}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.155273Z",
     "start_time": "2024-04-24T21:04:57.149793Z"
    }
   },
   "id": "2aa57128dac9bd7b"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def load_losses(model_name, folder=\"losses\"):\n",
    "    filepath = os.path.join(folder, f\"{model_name}_losses.csv\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Losses loaded from {filepath}\")\n",
    "    return df['train_loss'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.155457Z",
     "start_time": "2024-04-24T21:04:57.152539Z"
    }
   },
   "id": "a3ea4eb82686c07c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def save_model(model, model_name, folder=\"models\"):\n",
    "    filepath = os.path.join(folder, f\"{model_name}.pth\")\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model saved to {filepath}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.157153Z",
     "start_time": "2024-04-24T21:04:57.155554Z"
    }
   },
   "id": "758c2a6da3ca3de9"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def load_model(model, model_name, folder=\"models\"):\n",
    "    filepath = os.path.join(folder, f\"{model_name}.pth\")\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.163146Z",
     "start_time": "2024-04-24T21:04:57.157941Z"
    }
   },
   "id": "3386be4c347be17c"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    {'emb_dim': 10, 'hidden_dim': 64, 'learning_rate': 1e-3},\n",
    "    {'emb_dim': 16, 'hidden_dim': 64, 'learning_rate': 1e-4},\n",
    "    {'emb_dim': 10, 'hidden_dim': 128, 'learning_rate': 5e-4},\n",
    "    {'emb_dim': 20, 'hidden_dim': 128, 'learning_rate': 1e-5},\n",
    "    {'emb_dim': 64, 'hidden_dim': 128, 'learning_rate': 1e-5},\n",
    "    {'emb_dim': 84, 'hidden_dim': 128, 'learning_rate': 1e-5},\n",
    "    {'emb_dim': 64, 'hidden_dim': 256, 'learning_rate': 1e-4},\n",
    "    {'emb_dim': 128, 'hidden_dim': 128, 'learning_rate': 1e-4}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:04:57.163346Z",
     "start_time": "2024-04-24T21:04:57.160565Z"
    }
   },
   "id": "deee06aa6ca0c7da"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cbow_model_emb10_hidden64_lr1e-03...\n",
      "23:08:33.191981 | Epoch 5 | Training Loss: 5.60346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcbow_model_emb\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memb_dim\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_hidden\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhidden_dim\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_lr\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.0e\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m model_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m save_model(model, model_name)\n\u001B[1;32m     13\u001B[0m save_losses(model_losses, model_name)\n",
      "Cell \u001B[0;32mIn[63], line 12\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, optimizer, loss_fn, epochs)\u001B[0m\n\u001B[1;32m     10\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(contexts)\n\u001B[1;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, targets)\n\u001B[0;32m---> 12\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     14\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for config in configurations:\n",
    "    model = CBOW(vocab_size=VOCAB_SIZE, emb_dim=config['emb_dim'], hidden_dim=config['hidden_dim'],\n",
    "                 context_size=CONTEXT_SIZE).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    loss_fn = nn.NLLLoss(weight=class_weights)\n",
    "\n",
    "    model_name = f\"cbow_model_emb{config['emb_dim']}_hidden{config['hidden_dim']}_lr{config['learning_rate']:.0e}\"\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    model_losses = train_model(model, train_loader, optimizer, loss_fn, epochs=20)\n",
    "\n",
    "    save_model(model, model_name)\n",
    "    save_losses(model_losses, model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:08:41.445197Z",
     "start_time": "2024-04-24T21:04:57.163470Z"
    }
   },
   "id": "f046198f4cc20c91"
  },
  {
   "cell_type": "markdown",
   "id": "7fb1dc9393049b56",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4. Train several models, select the best one, and evaluate its performance. Note that the performance here is potentially extremely low, but the real objective is not to train a good predictor, only to have a good representation of the semantics of each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for contexts, targets in data_loader:\n",
    "            contexts, targets = contexts.to(device), targets.to(device)\n",
    "            outputs = model(contexts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:11:05.973709Z",
     "start_time": "2024-04-24T21:11:05.969821Z"
    }
   },
   "id": "1202182fa734da97"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def load_and_evaluate_models(configurations, val_loader):\n",
    "    best_model = None\n",
    "    best_model_name = \"\"\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for config in configurations:\n",
    "        model_name = f\"cbow_model_emb{config['emb_dim']}_hidden{config['hidden_dim']}_lr{config['learning_rate']:.0e}\"\n",
    "        model = CBOW(vocab_size=VOCAB_SIZE, emb_dim=config['emb_dim'], hidden_dim=config['hidden_dim'],\n",
    "                     context_size=CONTEXT_SIZE).to(device)\n",
    "        model = load_model(model, model_name)\n",
    "\n",
    "        val_accuracy = accuracy(model, val_loader)\n",
    "        print(f\"{model_name} | Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "    return best_model, best_model_name, best_accuracy\n",
    "\n",
    "\n",
    "best_model, best_model_name, best_val_accuracy = load_and_evaluate_models(configurations, val_loader)\n",
    "print(f\"Validation Accuracy of the best model ({best_model_name}): {best_val_accuracy:.2%}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47679df96f8efdd0"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/cbow_model_emb10_hidden64_lr1e-03.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 23\u001B[0m\n\u001B[1;32m     18\u001B[0m             best_model_name \u001B[38;5;241m=\u001B[39m model_name\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_model, best_model_name, best_accuracy\n\u001B[0;32m---> 23\u001B[0m best_model, best_model_name, best_val_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mload_and_evaluate_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfigurations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m test_accuracy \u001B[38;5;241m=\u001B[39m accuracy(best_model, test_loader)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest Accuracy of the best model (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_model_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[73], line 10\u001B[0m, in \u001B[0;36mload_and_evaluate_models\u001B[0;34m(configurations, val_loader)\u001B[0m\n\u001B[1;32m      7\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcbow_model_emb\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memb_dim\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_hidden\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhidden_dim\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_lr\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.0e\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m CBOW(vocab_size\u001B[38;5;241m=\u001B[39mVOCAB_SIZE, emb_dim\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memb_dim\u001B[39m\u001B[38;5;124m'\u001B[39m], hidden_dim\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhidden_dim\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      9\u001B[0m              context_size\u001B[38;5;241m=\u001B[39mCONTEXT_SIZE)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 10\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m val_accuracy \u001B[38;5;241m=\u001B[39m accuracy(model, val_loader)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Validation Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[69], line 3\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model, model_name, folder)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model, model_name, folder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m      2\u001B[0m     filepath \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      4\u001B[0m     model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel loaded from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/serialization.py:998\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    995\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    996\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 998\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m   1000\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/serialization.py:445\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 445\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/serialization.py:426\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 426\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mopen\u001B[39m(name, mode))\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'models/cbow_model_emb10_hidden64_lr1e-03.pth'"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy(best_model, test_loader)\n",
    "print(f\"Test Accuracy of the best model ({best_model_name}): {test_accuracy:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:11:06.359695Z"
    }
   },
   "id": "c226fa8d2ba48a74"
  },
  {
   "cell_type": "markdown",
   "id": "82711c018e25e726",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5. Compute the cosine similarity matrix of the vocabulary based on the trained embedding. For some words of your choice (e.g. *me*, *white*, *man*, *have*, *be*, *child*, *yes*, *what* etc.), report the 10 most similar words. Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532816665732979",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_embeddings = CBOW_model.embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "mat_size = len(best_model_embeddings)\n",
    "cos_sim_mat = np.zeros(shape=(mat_size, mat_size))\n",
    "\n",
    "for w1 in range(mat_size):\n",
    "    for w2 in range(mat_size):\n",
    "        cos_sim_mat[w1][w2] = np.dot(best_model_embeddings[w1], best_model_embeddings[w2]) / (\n",
    "                np.linalg.norm(best_model_embeddings[w1]) * np.linalg.norm(best_model_embeddings[w2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8845918b46946",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_words = [\"me\", \"white\", \"man\", \"have\", \"be\", \"child\", \"yes\", \"what\"]\n",
    "test_words_idx = [vocab.get_stoi()[word] for word in test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29062a8e17825af3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "similar_words = {}\n",
    "\n",
    "for word, idx in zip(test_words, test_words_idx):\n",
    "    # get cosine similarities for the current word against all other words\n",
    "    similarities = cos_sim_mat[idx]\n",
    "\n",
    "    # get indices of the top 10 most similar words (excluding the word itself)\n",
    "    # argsort returns indices of sorted array, with the smallest first, so we take the last 10 items\n",
    "    most_similar_idxs = np.argsort(similarities)[-top_n - 1:-1][::-1]\n",
    "\n",
    "    # map indices back to words\n",
    "    similar_words[word] = [vocab.get_itos()[i] for i in most_similar_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793030b39ab25c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word, similar in similar_words.items():\n",
    "    print(f\"Words most similar to '{word}': {similar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fee011d91aa34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6. Visualize the embedding space on <https://projector.tensorflow.org>. To do so, upload the vocabulary and their corresponding values in the embedding space as two tsv files. Try to find and select clusters. Report both plots (you can use screenshots) and their corresponding selections for some meaningful clusters. Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80f0631c5b3c33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_embeddings = pd.DataFrame(best_model_embeddings)\n",
    "df_embeddings.to_csv(\"tensorflow_projector/vectors.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "vocab_items = vocab.get_itos()\n",
    "df_vocab = pd.DataFrame(vocab_items)\n",
    "df_vocab.to_csv(\"tensorflow_projector/metadata.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7f1d34563b2d41f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
